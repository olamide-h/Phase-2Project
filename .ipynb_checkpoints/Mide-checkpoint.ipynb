{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "# HGTV SHOW\n",
    "-HGTV is launching a show based on homes in kings county. The goal of the show is to show homeowners what predictors lead to a higher listing price so the owner can sell and maximize profit.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import statsmodels\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from statsmodels.api import qqplot\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from folium.plugins import FastMarkerCluster\n",
    "import folium\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading in the data and making a pandas dataframe.\n",
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA(EXPLORITORY DATA ANALYSIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the columns and values.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Exploring some low hanging data.\n",
    "#some standouts: Avaerage house in this county have 3 bedrooms and 2 bathrooms.\n",
    "# Theres a hosue in the set that gas 33 bedrooms and 8 bathroom which will defiently be an outlier.\n",
    "# oldest house is dated to 1900. While he most recent hosue was built in 2015. \n",
    "df.describe()\n",
    "#ON AVERGAE ABOUT 3 BEDROOMS AND 2 BATHROOMS PER HOUSE\n",
    "# MOST RECENT HOUSE WAS BUILT IN 2015. OLDEST HOUSE WAS BUILT IN 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#exploring and filtering\n",
    "#dropping houses that are repeated. some houses are repeated if they had rennovations done.\n",
    "# Filling in waterfront's NA values with 0 \n",
    "#dropping years renovated column because a large amount og\n",
    "df.drop_duplicates(subset='id',keep='first',inplace=True)\n",
    "df['waterfront'].fillna(0, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in list(df.columns):\n",
    "    print(column, sum(df[column].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drop_vars = ['date','sqft_above', 'sqft_basement',\n",
    "             'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "df_corr = df.drop(columns=drop_vars)\n",
    "\n",
    "# generate heatmap to display correlations\n",
    "corr = df_corr.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df.corr().abs()\n",
    "fig, ax=plt.subplots(figsize=(17,12))\n",
    "fig.suptitle('Variable Correlations', fontsize=30, y=.95, fontname='Silom')\n",
    "heatmap = sns.heatmap(corr, cmap='Reds', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "correlations = []\n",
    "for idx, correlation in corr['price'].T.iteritems():\n",
    "    if correlation >= .30 and idx != 'price':\n",
    "        features.append(idx)\n",
    "        correlations.append(correlation)\n",
    "corr_with_price = pd.DataFrame({'Correlations':correlations, 'Features': features})\n",
    "\n",
    "Multicollinear_Features = []\n",
    "Multicollinear_Corr = []\n",
    "def check_multicollinearity(feature):\n",
    "    for idx, correlation in corr[feature].T.iteritems():\n",
    "        if correlation >= .80 and idx != feature:\n",
    "            Multicollinear_Features.append([feature, idx])\n",
    "            Multicollinear_Corr.append(correlation)\n",
    "            \n",
    "for feature in corr:\n",
    "    check_multicollinearity(feature)\n",
    "MC_df = pd.DataFrame({'Correlations':Multicollinear_Corr, 'Features': Multicollinear_Features})\n",
    "print('Multicollinear Features')\n",
    "display(MC_df)\n",
    "print('Correlations with Price')\n",
    "display(MC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(df['view'], df['price'])\n",
    "plt.title('House View and Price', fontsize=12, fontname='silom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilene\\anaconda3\\envs\\learn-env\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "x = df['price']\n",
    "y = df['sqft_living']\n",
    "sns.barplot(x,y)\n",
    "plt.title('House Condition and price', fontsize=15, fontname='silom');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  STEP 2 \n",
    "# CHECKING  FOR PRE-MODEL ASSUMPTIONS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING FOR LINEARITY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "\n",
    "for x in features:\n",
    "    plt.scatter(X_train[x], y_train)\n",
    "    plt.title(f'Plot of Price against {x}')\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel('Price')\n",
    "    plt.show()\n",
    "    \n",
    "# also plot sales against itself\n",
    "plt.scatter(y_train.index, y_train)\n",
    "plt.hlines(y_train.mean(), 0, 200)\n",
    "plt.xlabel('Index Value')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Variance of Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.price\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living','sqft_lot','yr_built','grade' ]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 ONE HOT ENCODE CATEGORICAL VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 CREATING DUMMY BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy Regressor for the baseline. DUMMY IS ONLY APPLIED ON TRAINING SET\n",
    "dummy_regr = DummyRegressor(strategy='mean')\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "dummy_regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_regr.score(X_train, y_train)# the R score is zero.  The mean of Y explains 0% of the variation of sales price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT BUILD FIRST SIMPLE MODEL THAT DOES BETTER THAN THE DUMMY REGRESSOR. WHICH WAS 0\n",
    "# CAN USE THE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train.shape\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING A SIMPLE MODEL WTIH VARIABLES []. THESE VARIBALES WERE CHOSEN BASED ON RFE OR VARS THAT ARE HIGHLY CORRELATED WITH SALES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW CREATE FIRST SIMPLE MODEL THAT DOES BETTER THAN DUMMY REGRESSOR MEAN.\n",
    "#EXAMPLES; RECURSIVE FEATURE ELIMINATION. LOOK AT HIGH CORRELATIONS VARIABLES TO Y.\n",
    "\n",
    "#MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.price\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living','sqft_lot','yr_built','grade', 'floors' ]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_regr = DummyRegressor(strategy='mean')\n",
    "dummy_regr.fit(X_train, y_train)\n",
    "dummy_regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_regr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_trial = pd.DataFrame()\n",
    "grade_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "grade_trial['grade'] = X_train['grade']\n",
    "grade_trial['ID'] = len(X_train.values)\n",
    "ohe_data = pd.DataFrame(ohe.fit_transform(grade_trial)) \n",
    "#grade_trial\n",
    "ohe_data.columns = ohe.get_feature_names(['grade', 'ID'])\n",
    "ohe_data = ohe_data.drop('ID_17136', axis=1)\n",
    "#ohe_data\n",
    "\n",
    "grade_test['grade'] = X_test['grade']\n",
    "grade_test['ID'] = len(X_test.values)\n",
    "ohe_test = pd.DataFrame(ohe.transform(grade_test))\n",
    "ohe_test.columns = ohe.get_feature_names(['grade', 'ID'])\n",
    "ohe_test = ohe_test.drop('ID_17136', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "y = df.price\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living','sqft_lot','yr_built','grade', 'floors' ]]\n",
    "\n",
    "# Train test split with random_state=42 and test_size=0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Scale appropriately on TRAINING DATA \n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train.drop('grade', axis=1))\n",
    "Testpreds = ss.transform(X_test.drop('grade', axis=1))\n",
    "X_preds_st_scaled = ss.transform(X_train.drop('grade', axis=1))\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# fit and score the model (checkout the test set if there is time)\n",
    "lr.fit(X_preds_st_scaled, y_train)\n",
    "lr.coef_\n",
    "lr.score(X_preds_st_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_x = ohe_data.join(pd.DataFrame(X_preds_st_scaled))\n",
    "combined_test = ohe_test.join(pd.DataFrame(Testpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# fit and score the model (checkout the test set if there is time)\n",
    "lr.fit(combined_x.values, y_train)\n",
    "lr.coef_\n",
    "model = lr.score(combined_x.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(combined_test.values)\n",
    "lr.coef_\n",
    "lr.score(combined_test.values, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_metrics(y, model):\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "    print(\"Metrics:\")\n",
    "    # R2\n",
    "    print(f\"R2: {r2_score(y, model):.3f}\")\n",
    "    # MAE\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y, model):.3f}\")\n",
    "    # MSE\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y, model):.3f}\")\n",
    "    # RMSE - just MSE but set squared=False\n",
    "    print(f\"Root Mean Squared Error: {mean_squared_error(y, model, squared=False):.3f}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.head())\n",
    "display(X_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_2 = ols(formula=\"price ~bathrooms + bedrooms\", data=df).fit()\n",
    "Model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_2 = ols(formula=\"price ~sqft_living + sqft_living15 \", data=df).fit()\n",
    "Model_2.summary()S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_3 = ols(formula=\"price ~sqft_living + sqft_living15 \", data=df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY TAKEWAYS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
